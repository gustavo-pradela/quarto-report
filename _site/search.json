[
  {
    "objectID": "index.html#escopo",
    "href": "index.html#escopo",
    "title": "PicPay - Case T√©cnico",
    "section": "Escopo",
    "text": "Escopo\n\nO escopo do projeto abrange as etapas de explora√ß√£o e tratamento dos dados, sele√ß√£o de vari√°veis, constru√ß√£o e avalia√ß√£o de modelos supervisionados, an√°lise de estabilidade (tanto das vari√°veis quanto do modelo ao longo do tempo) e recomenda√ß√£o de a√ß√µes com base nos resultados. Adicionalmente, s√£o destacadas as m√©tricas de desempenho e a an√°lise de calibra√ß√£o do modelo, buscando assegurar aplicabilidade pr√°tica em cen√°rios reais de tomada de decis√£o de cr√©dito.\n\n\nA base foi dividida respeitando a cronologia das concess√µes de cr√©dito, utilizando se as safras de outubro, novembro e dezembro como conjunto de valida√ß√£o Out of-Time (OOT), a fim de simular o comportamento futuro do modelo e testar sua estabilidade temporal.\n\n\n\n√öltima atualiza√ß√£o: 02/12/2025 01:41:47"
  },
  {
    "objectID": "abas/01_estrutura_do_projeto.html",
    "href": "abas/01_estrutura_do_projeto.html",
    "title": "1. üìÑ An√°lise Explorat√≥ria de Dados (EDA)",
    "section": "",
    "text": "Este cap√≠tulo apresenta a estrutura da base de dados, a defini√ß√£o da vari√°vel alvo (target) e as an√°lises iniciais de qualidade e distribui√ß√£o de risco.\n\n\n\nA base de dados bruta cont√©m 10.738 observa√ß√µes e 81 colunas (incluindo id, safra e features).\nDefini√ß√£o da Vari√°vel Alvo (y)\ny = 1 (Mau Pagador): Inadimpl√™ncia (default).\ny = 0 (Bom Pagador): N√£o-inadimpl√™ncia.\nA Taxa de Inadimpl√™ncia Global da amostra √© de 29,13%. Esta propor√ß√£o representa o risco real da popula√ß√£o no per√≠odo e, dado que o modelo ser√° uma Regress√£o Log√≠stica (focada na estima√ß√£o de probabilidades), optei por manter a distribui√ß√£o original do target. Essa abordagem assegura que o modelo final esteja adequadamente calibrado para a taxa de default real.\n\n\n\nClasse\nContagem Absoluta\nPropor√ß√£o\n\n\n\n\n0 (Bom Pagador)\n7.610\n70,87%\n\n\n1 (Mau Pagador)\n3.128\n29,13%\n\n\n\n\n\n\n\nA an√°lise do risco ao longo do tempo (safra) √© crucial em cr√©dito. A base abrange 12 meses, de 01/2014 a 12/2014.\nO gr√°fico abaixo mostra a varia√ß√£o da taxa de inadimpl√™ncia (m√©dia de y) em cada safra.\n\nA taxa de inadimpl√™ncia demonstra uma tend√™ncia de aumento nas safras finais (11/2014 e 12/2014), atingindo o pico de 35,24% na √∫ltima safra. Este pico √© significativamente maior do que a m√©dia da amostra (29,13%), sugerindo uma poss√≠vel instabilidade temporal ou uma mudan√ßa no perfil de risco dos clientes mais recentes.\n\n\n\n\nA qualidade dos dados foi avaliada, com foco na presen√ßa de valores ausentes (Missing Values).\nTotal de Features Analisadas: 78 Amostra Total: 10.738 linhas\n\nConclus√£o e Pr√≥xima Etapa: H√° uma grande quantidade de vari√°veis com uma alta percentagem de valores ausentes (mais de 50%). Na fase 02_feature_engineering.ipynb, ser√° necess√°rio definir um limite de corte para descarte de vari√°veis.",
    "crumbs": [
      "01. Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "abas/01_estrutura_do_projeto.html#defini√ß√£o-do-target-e-distribui√ß√£o-da-amostra",
    "href": "abas/01_estrutura_do_projeto.html#defini√ß√£o-do-target-e-distribui√ß√£o-da-amostra",
    "title": "1. üìÑ An√°lise Explorat√≥ria de Dados (EDA)",
    "section": "",
    "text": "A base de dados bruta cont√©m 10.738 observa√ß√µes e 81 colunas (incluindo id, safra e features).\nDefini√ß√£o da Vari√°vel Alvo (y)\ny = 1 (Mau Pagador): Inadimpl√™ncia (default).\ny = 0 (Bom Pagador): N√£o-inadimpl√™ncia.\nA Taxa de Inadimpl√™ncia Global da amostra √© de 29,13%. Esta propor√ß√£o representa o risco real da popula√ß√£o no per√≠odo e, dado que o modelo ser√° uma Regress√£o Log√≠stica (focada na estima√ß√£o de probabilidades), optei por manter a distribui√ß√£o original do target. Essa abordagem assegura que o modelo final esteja adequadamente calibrado para a taxa de default real.\n\n\n\nClasse\nContagem Absoluta\nPropor√ß√£o\n\n\n\n\n0 (Bom Pagador)\n7.610\n70,87%\n\n\n1 (Mau Pagador)\n3.128\n29,13%",
    "crumbs": [
      "01. Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "abas/01_estrutura_do_projeto.html#estabilidade-temporal-da-inadimpl√™ncia-an√°lise-por-safra",
    "href": "abas/01_estrutura_do_projeto.html#estabilidade-temporal-da-inadimpl√™ncia-an√°lise-por-safra",
    "title": "1. üìÑ An√°lise Explorat√≥ria de Dados (EDA)",
    "section": "",
    "text": "A an√°lise do risco ao longo do tempo (safra) √© crucial em cr√©dito. A base abrange 12 meses, de 01/2014 a 12/2014.\nO gr√°fico abaixo mostra a varia√ß√£o da taxa de inadimpl√™ncia (m√©dia de y) em cada safra.\n\nA taxa de inadimpl√™ncia demonstra uma tend√™ncia de aumento nas safras finais (11/2014 e 12/2014), atingindo o pico de 35,24% na √∫ltima safra. Este pico √© significativamente maior do que a m√©dia da amostra (29,13%), sugerindo uma poss√≠vel instabilidade temporal ou uma mudan√ßa no perfil de risco dos clientes mais recentes.",
    "crumbs": [
      "01. Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "abas/01_estrutura_do_projeto.html#qualidade-e-sa√∫de-dos-dados-valores-ausentes",
    "href": "abas/01_estrutura_do_projeto.html#qualidade-e-sa√∫de-dos-dados-valores-ausentes",
    "title": "1. üìÑ An√°lise Explorat√≥ria de Dados (EDA)",
    "section": "",
    "text": "A qualidade dos dados foi avaliada, com foco na presen√ßa de valores ausentes (Missing Values).\nTotal de Features Analisadas: 78 Amostra Total: 10.738 linhas\n\nConclus√£o e Pr√≥xima Etapa: H√° uma grande quantidade de vari√°veis com uma alta percentagem de valores ausentes (mais de 50%). Na fase 02_feature_engineering.ipynb, ser√° necess√°rio definir um limite de corte para descarte de vari√°veis.",
    "crumbs": [
      "01. Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "abas/02_feature_engineering.html",
    "href": "abas/02_feature_engineering.html",
    "title": "‚öôÔ∏è 2. Feature Engineering e Sele√ß√£o de Vari√°veis",
    "section": "",
    "text": "Esta se√ß√£o detalha as t√©cnicas de pr√©-processamento e sele√ß√£o aplicadas para garantir um conjunto de features robusto e de alta qualidade para a modelagem. O objetivo √© remover ru√≠dos, redund√¢ncias e vari√°veis inst√°veis.\n\n\n\nO primeiro passo foi remover vari√°veis que n√£o agregam valor preditivo ou que apresentam alta incerteza devido √† falta de dados.\nCrit√©rio de Descarte adotado para Missing Values: Vari√°veis com mais de 60% de valores ausentes foram descartadas.\n\n\n\n\n\n\n\n\n\nTipo de Vari√°vel Removida\nContagem\nExemplo\nJustificativa\n\n\n\n\nAlto Missing (&gt;60%)\n19\nVAR_62, VAR_70, etc.\nAlta incerteza e baixa confiabilidade estat√≠stica.\n\n\nConstante\n0\nN/A\nN√£o h√° vari√°veis com valor √∫nico.\n\n\nID-Like\n1\nID_COL\nVari√°veis √∫nicas por linha n√£o carregam informa√ß√£o generaliz√°vel.\n\n\n\n19 features foram removidas, resultando em 62 features restantes para a an√°lise (81 originais - 19 removidas).\n\n\n\n\nA classifica√ß√£o correta das vari√°veis √© um passo essencial para garantir que o pr√©-processamento subsequente seja aplicado de forma adequada (ex: One-Hot Encoding para categ√≥ricas, Scaling para num√©ricas).\n\n\nDada a natureza mascarada das features, a distin√ß√£o entre vari√°veis cont√≠nuas e discretas foi feita utilizando a Cardinalidade (n√∫mero de valores √∫nicos) como crit√©rio principal.\nThreshold Definido: Foi estabelecido um threshold de 25 valores √∫nicos.\n\nVari√°veis Categ√≥ricas (CAT_VARS): Features com at√© 25 valores √∫nicos foram classificadas como categ√≥ricas, pois representam um conjunto discreto e gerenci√°vel de classes.\nVari√°veis Num√©ricas (NUM_VARS): Features com mais de 25 valores √∫nicos foram classificadas como num√©ricas, indicando uma distribui√ß√£o de dados cont√≠nua ou de alta vari√¢ncia.\n\n\n\n\nAp√≥s a classifica√ß√£o, as features em CAT_VARS foram explicitamente convertidas para o tipo object (tipo Python para string ou categoria). Esta convers√£o √© necess√°ria para garantir que os pipelines de pr√©-processamento (como OneHotEncoder ou o uso futuro de WOE) as tratem corretamente, independentemente de seu tipo original.\n\n\n\n\n\nVari√°veis com baix√≠ssima varia√ß√£o (proximidade de valor constante) n√£o distinguem bem os clientes e s√£o removidas.\nBaixa Vari√¢ncia: Foi definido um threshold de 0.001. Apenas 1 feature foi removida por ter vari√¢ncia muito pr√≥xima de zero.\nA base n√£o possui colunas duplicadas.\n\n\n\n\nA multicolinearidade entre features num√©ricas √© prejudicial para a modelagem, pois torna os coeficientes do modelo inst√°veis e dif√≠ceis de interpretar.\nCrit√©rio de Descarte: Manter apenas uma vari√°vel de cada par que apresentava correla√ß√£o absoluta superior a 0.9 na base de Treino.\n\n\n\nvar1\nvar2\ncorr\n\n\n\n\nVAR_74\nVAR_78\n0.998554\n\n\nVAR_71\nVAR_73\n0.997062\n\n\nVAR_57\nVAR_60\n0.991046\n\n\nVAR_19\nVAR_22\n0.975977\n\n\nVAR_10\nVAR_69\n0.975103\n\n\nVAR_24\nVAR_58\n0.974130\n\n\nVAR_25\nVAR_28\n0.972608\n\n\nVAR_39\nVAR_45\n0.972208\n\n\nVAR_40\nVAR_44\n0.968908\n\n\nVAR_14\nVAR_26\n0.954847\n\n\nVAR_44\nVAR_64\n0.904339\n\n\n\n11 features foram removidas devido √† alta correla√ß√£o. O conjunto de dados final possui 50 features candidatas (61 restantes - 11 removidas).\n\n\n\n\nA estabilidade das features entre a amostra de Treino e a amostra de Teste (Out-of-Time) √© cr√≠tica para a robustez do modelo. Utilizei o Population Stability Index (PSI).\nPSI: O PSI mede o drift (deslocamento) na distribui√ß√£o de uma vari√°vel entre duas popula√ß√µes.\n\nPSI &lt; 0.1: Distribui√ß√£o Est√°vel\n0.1 &lt; ou = PSI &lt; 0.25: Mudan√ßa Moderada\nPSI &gt; ou = 0.25: Mudan√ßa Forte\n\nNenhuma feature atingiu o limite de Mudan√ßa Forte. As vari√°veis VAR_30 e VAR_1 apresentam Mudan√ßa Moderada. Embora n√£o sejam descartadas neste momento, elas ser√£o monitoradas na pr√≥xima etapa.\nConclus√£o e Pr√≥xima Etapa: Ap√≥s o processo de Feature Engineering e Sele√ß√£o, o n√∫mero de vari√°veis preditoras foi reduzido de 78 para 47 features (al√©m das colunas protegidas).",
    "crumbs": [
      "02. Feature Enginee"
    ]
  },
  {
    "objectID": "abas/02_feature_engineering.html#filtragem-inicial-missing-constantes-e-ids",
    "href": "abas/02_feature_engineering.html#filtragem-inicial-missing-constantes-e-ids",
    "title": "‚öôÔ∏è 2. Feature Engineering e Sele√ß√£o de Vari√°veis",
    "section": "",
    "text": "O primeiro passo foi remover vari√°veis que n√£o agregam valor preditivo ou que apresentam alta incerteza devido √† falta de dados.\nCrit√©rio de Descarte adotado para Missing Values: Vari√°veis com mais de 60% de valores ausentes foram descartadas.\n\n\n\n\n\n\n\n\n\nTipo de Vari√°vel Removida\nContagem\nExemplo\nJustificativa\n\n\n\n\nAlto Missing (&gt;60%)\n19\nVAR_62, VAR_70, etc.\nAlta incerteza e baixa confiabilidade estat√≠stica.\n\n\nConstante\n0\nN/A\nN√£o h√° vari√°veis com valor √∫nico.\n\n\nID-Like\n1\nID_COL\nVari√°veis √∫nicas por linha n√£o carregam informa√ß√£o generaliz√°vel.\n\n\n\n19 features foram removidas, resultando em 62 features restantes para a an√°lise (81 originais - 19 removidas).",
    "crumbs": [
      "02. Feature Enginee"
    ]
  },
  {
    "objectID": "abas/02_feature_engineering.html#filtragem-por-baixa-vari√¢ncia-e-duplicatas",
    "href": "abas/02_feature_engineering.html#filtragem-por-baixa-vari√¢ncia-e-duplicatas",
    "title": "‚öôÔ∏è 2. Feature Engineering e Sele√ß√£o de Vari√°veis",
    "section": "",
    "text": "Vari√°veis com baix√≠ssima varia√ß√£o (proximidade de valor constante) n√£o distinguem bem os clientes e s√£o removidas.\nBaixa Vari√¢ncia: Foi definido um threshold de 0.001. Apenas 1 feature foi removida por ter vari√¢ncia muito pr√≥xima de zero.\nA base n√£o possui colunas duplicadas.",
    "crumbs": [
      "02. Feature Enginee"
    ]
  },
  {
    "objectID": "abas/02_feature_engineering.html#tratamento-de-multicolinearidade-alta-correla√ß√£o",
    "href": "abas/02_feature_engineering.html#tratamento-de-multicolinearidade-alta-correla√ß√£o",
    "title": "‚öôÔ∏è 2. Feature Engineering e Sele√ß√£o de Vari√°veis",
    "section": "",
    "text": "A multicolinearidade entre features num√©ricas √© prejudicial para a modelagem, pois torna os coeficientes do modelo inst√°veis e dif√≠ceis de interpretar.\nCrit√©rio de Descarte: Manter apenas uma vari√°vel de cada par que apresentava correla√ß√£o absoluta superior a 0.9 na base de Treino.\n\n\n\nvar1\nvar2\ncorr\n\n\n\n\nVAR_74\nVAR_78\n0.998554\n\n\nVAR_71\nVAR_73\n0.997062\n\n\nVAR_57\nVAR_60\n0.991046\n\n\nVAR_19\nVAR_22\n0.975977\n\n\nVAR_10\nVAR_69\n0.975103\n\n\nVAR_24\nVAR_58\n0.974130\n\n\nVAR_25\nVAR_28\n0.972608\n\n\nVAR_39\nVAR_45\n0.972208\n\n\nVAR_40\nVAR_44\n0.968908\n\n\nVAR_14\nVAR_26\n0.954847\n\n\nVAR_44\nVAR_64\n0.904339\n\n\n\n11 features foram removidas devido √† alta correla√ß√£o. O conjunto de dados final possui 50 features candidatas (61 restantes - 11 removidas).",
    "crumbs": [
      "02. Feature Enginee"
    ]
  },
  {
    "objectID": "abas/02_feature_engineering.html#an√°lise-de-estabilidade-temporal-psi",
    "href": "abas/02_feature_engineering.html#an√°lise-de-estabilidade-temporal-psi",
    "title": "‚öôÔ∏è 2. Feature Engineering e Sele√ß√£o de Vari√°veis",
    "section": "",
    "text": "A estabilidade das features entre a amostra de Treino e a amostra de Teste (Out-of-Time) √© cr√≠tica para a robustez do modelo. Utilizei o Population Stability Index (PSI).\nPSI: O PSI mede o drift (deslocamento) na distribui√ß√£o de uma vari√°vel entre duas popula√ß√µes.\n\nPSI &lt; 0.1: Distribui√ß√£o Est√°vel\n0.1 &lt; ou = PSI &lt; 0.25: Mudan√ßa Moderada\nPSI &gt; ou = 0.25: Mudan√ßa Forte\n\nNenhuma feature atingiu o limite de Mudan√ßa Forte. As vari√°veis VAR_30 e VAR_1 apresentam Mudan√ßa Moderada. Embora n√£o sejam descartadas neste momento, elas ser√£o monitoradas na pr√≥xima etapa.\nConclus√£o e Pr√≥xima Etapa: Ap√≥s o processo de Feature Engineering e Sele√ß√£o, o n√∫mero de vari√°veis preditoras foi reduzido de 78 para 47 features (al√©m das colunas protegidas).",
    "crumbs": [
      "02. Feature Enginee"
    ]
  },
  {
    "objectID": "abas/03_model_training.html",
    "href": "abas/03_model_training.html",
    "title": "üß† 3. Modelagem e Sele√ß√£o Final do Modelo",
    "section": "",
    "text": "Esta se√ß√£o detalha o pr√©-processamento final das features, a sele√ß√£o de vari√°veis baseada em import√¢ncia e a avalia√ß√£o comparativa de diferentes algoritmos de Machine Learning.\n\n\n\nTodas as 47 features restantes foram submetidas a um Pipeline de pr√©-processamento padr√£o:\n\nImputa√ß√£o de Missing Values: Utiliza√ß√£o da mediana para preencher valores ausentes nas vari√°veis num√©ricas e moda nas vari√°veis categ√≥ricas.\nPadroniza√ß√£o (StandardScaler e One-Hot Encoding): Aplica√ß√£o do StandardScaler para normalizar as features n√∫mericas e One-Hot Encoding para as features categ√≥ricas.\n\n\n\n\n\nPara refinar o modelo e reduzir a complexidade e o risco de overfitting, foi utilizado um modelo Random Forest para ranquear as features por import√¢ncia (Feature Importance).\nObjetivo: Selecionar as Top K=20 vari√°veis que mais contribuem para a separa√ß√£o entre Bons e Maus Pagadores.\n\nO dataset para o treinamento final foi reduzido de 47 para 20 features, focado nas vari√°veis com maior poder preditivo.\n\n\n\n\nQuatro modelos foram comparados utilizando Cross-Validation Estratificada (5 splits) no conjunto de Treino (X_train_sel).\n\n\nEm Credit Scoring, as m√©tricas de ranking s√£o priorizadas:\n\nAUC (Area Under the Curve): Probabilidade de o modelo ranquear um par aleat√≥rio (Mau Pagador, Bom Pagador) na ordem correta.\nGini Coefficient: Mede a separa√ß√£o das distribui√ß√µes.\nKS (Kolmogorov-Smirnov): Mede a separa√ß√£o m√°xima entre as distribui√ß√µes acumuladas de Bons e Maus Pagadores.\n\n\n\n\n\n\n\n\n\n\n\n\n\nModelo\nKS M√©dio\nKS Desvio\nAUC M√©dio\nAUC Desvio\nGini M√©dio\nGini Desvio\n\n\n\n\nLightGBM\n0.447\n0.022\n0.796\n0.011\n0.593\n0.022\n\n\nLogistic Regression\n0.424\n0.013\n0.786\n0.011\n0.571\n0.022\n\n\nRandom Forest\n0.433\n0.019\n0.785\n0.009\n0.569\n0.017\n\n\nXGBoost\n0.424\n0.034\n0.783\n0.015\n0.566\n0.029\n\n\n\nConclus√£o do Treino: O LightGBM demonstrou o melhor desempenho preditivo bruto, estabelecendo o teto da performance com o maior AUC (0.796) e Gini (0.593). A Regress√£o Log√≠stica e o Random Forest se mostraram altamente competitivos, ficando a menos de 1 ponto percentual de dist√¢ncia no AUC.\n\n\n\n\n\nA performance de cada modelo foi avaliada no conjunto de Teste (Out-of-Time - OOT), que representa o ambiente de risco futuro. A estabilidade √© medida pela capacidade do modelo de reter seu poder preditivo em dados futuros (OOT).\n\n\n\nModelo\nKS\nAUC\nGini\n\n\n\n\nLightGBM\n0.306\n0.704\n0.407\n\n\nLogistic Regression\n0.294\n0.701\n0.402\n\n\nRandom Forest\n0.265\n0.685\n0.369\n\n\nXGBoost\n0.255\n0.668\n0.337\n\n\n\nConclus√£o: Devido a sua performance superior, o LightGBM √© o modelo escolhido para o Credit Scoring final.",
    "crumbs": [
      "03. Model Training"
    ]
  },
  {
    "objectID": "abas/03_model_training.html#pr√©-processamento-e-pipelines",
    "href": "abas/03_model_training.html#pr√©-processamento-e-pipelines",
    "title": "üß† 3. Modelagem e Sele√ß√£o Final do Modelo",
    "section": "",
    "text": "Todas as 47 features restantes foram submetidas a um Pipeline de pr√©-processamento padr√£o:\n\nImputa√ß√£o de Missing Values: Utiliza√ß√£o da mediana para preencher valores ausentes nas vari√°veis num√©ricas e moda nas vari√°veis categ√≥ricas.\nPadroniza√ß√£o (StandardScaler e One-Hot Encoding): Aplica√ß√£o do StandardScaler para normalizar as features n√∫mericas e One-Hot Encoding para as features categ√≥ricas.",
    "crumbs": [
      "03. Model Training"
    ]
  },
  {
    "objectID": "abas/03_model_training.html#sele√ß√£o-final-de-vari√°veis-random-forest",
    "href": "abas/03_model_training.html#sele√ß√£o-final-de-vari√°veis-random-forest",
    "title": "üß† 3. Modelagem e Sele√ß√£o Final do Modelo",
    "section": "",
    "text": "Para refinar o modelo e reduzir a complexidade e o risco de overfitting, foi utilizado um modelo Random Forest para ranquear as features por import√¢ncia (Feature Importance).\nObjetivo: Selecionar as Top K=20 vari√°veis que mais contribuem para a separa√ß√£o entre Bons e Maus Pagadores.\n\nO dataset para o treinamento final foi reduzido de 47 para 20 features, focado nas vari√°veis com maior poder preditivo.",
    "crumbs": [
      "03. Model Training"
    ]
  },
  {
    "objectID": "abas/03_model_training.html#avalia√ß√£o-comparativa-de-modelos-cross-validation",
    "href": "abas/03_model_training.html#avalia√ß√£o-comparativa-de-modelos-cross-validation",
    "title": "üß† 3. Modelagem e Sele√ß√£o Final do Modelo",
    "section": "",
    "text": "Quatro modelos foram comparados utilizando Cross-Validation Estratificada (5 splits) no conjunto de Treino (X_train_sel).\n\n\nEm Credit Scoring, as m√©tricas de ranking s√£o priorizadas:\n\nAUC (Area Under the Curve): Probabilidade de o modelo ranquear um par aleat√≥rio (Mau Pagador, Bom Pagador) na ordem correta.\nGini Coefficient: Mede a separa√ß√£o das distribui√ß√µes.\nKS (Kolmogorov-Smirnov): Mede a separa√ß√£o m√°xima entre as distribui√ß√µes acumuladas de Bons e Maus Pagadores.\n\n\n\n\n\n\n\n\n\n\n\n\n\nModelo\nKS M√©dio\nKS Desvio\nAUC M√©dio\nAUC Desvio\nGini M√©dio\nGini Desvio\n\n\n\n\nLightGBM\n0.447\n0.022\n0.796\n0.011\n0.593\n0.022\n\n\nLogistic Regression\n0.424\n0.013\n0.786\n0.011\n0.571\n0.022\n\n\nRandom Forest\n0.433\n0.019\n0.785\n0.009\n0.569\n0.017\n\n\nXGBoost\n0.424\n0.034\n0.783\n0.015\n0.566\n0.029\n\n\n\nConclus√£o do Treino: O LightGBM demonstrou o melhor desempenho preditivo bruto, estabelecendo o teto da performance com o maior AUC (0.796) e Gini (0.593). A Regress√£o Log√≠stica e o Random Forest se mostraram altamente competitivos, ficando a menos de 1 ponto percentual de dist√¢ncia no AUC.",
    "crumbs": [
      "03. Model Training"
    ]
  },
  {
    "objectID": "abas/03_model_training.html#valida√ß√£o-final-teste-oot",
    "href": "abas/03_model_training.html#valida√ß√£o-final-teste-oot",
    "title": "üß† 3. Modelagem e Sele√ß√£o Final do Modelo",
    "section": "",
    "text": "A performance de cada modelo foi avaliada no conjunto de Teste (Out-of-Time - OOT), que representa o ambiente de risco futuro. A estabilidade √© medida pela capacidade do modelo de reter seu poder preditivo em dados futuros (OOT).\n\n\n\nModelo\nKS\nAUC\nGini\n\n\n\n\nLightGBM\n0.306\n0.704\n0.407\n\n\nLogistic Regression\n0.294\n0.701\n0.402\n\n\nRandom Forest\n0.265\n0.685\n0.369\n\n\nXGBoost\n0.255\n0.668\n0.337\n\n\n\nConclus√£o: Devido a sua performance superior, o LightGBM √© o modelo escolhido para o Credit Scoring final.",
    "crumbs": [
      "03. Model Training"
    ]
  },
  {
    "objectID": "abas/04_tunning.html",
    "href": "abas/04_tunning.html",
    "title": "4. üî¨ Tunning e Modelo de Regress√£o Log√≠stica Final",
    "section": "",
    "text": "Nesta etapa, o modelo de Regress√£o Log√≠stica escolhido na Etapa 3 √© otimizado usando pesquisa de hiperpar√¢metros e, em seguida, validado no conjunto de Teste Out-of-Time (OOT).\n\n\n\nO modelo foi otimizado utilizando o RandomizedSearchCV com Cross-Validation, buscando maximizar o KS Score, uma m√©trica cr√≠tica para separa√ß√£o de risco\nO processo de tunning focou na regulariza√ß√£o do modelo para evitar overfitting e garantir a robustez.\nMelhores Par√¢metros Encontrados:\n\n\n\nPar√¢metro\nValor Otimizado\n\n\n\n\nn_estimators\n800\n\n\nlearning_rate\n0.01\n\n\nsubsample\n0.7\n\n\nreg_alpha / reg_lambda\n0.0 / 0.0\n\n\n\n\n\n\n\nO modelo otimizado foi treinado na base completa de Treino e avaliado no conjunto de Teste OOT, confirmando seu potencial m√°ximo.\n\n\n\nM√©trica\nValor\n\n\n\n\nKS\n0.313688\n\n\nAUC\n0.708333\n\n\nGini\n0.416665\n\n\n\nAp√≥s o tunning, o LightGBM alcan√ßou o melhor desempenho absoluto no Teste OOT, com AUC de 0.708 e Gini de 0.417. Este resultado supera o modelo de Regress√£o Log√≠stica (AUC 0.701) e confirma o LightGBM como o modelo mais preditivo para o Scorecard.",
    "crumbs": [
      "04. Tunning"
    ]
  },
  {
    "objectID": "abas/04_tunning.html#estrat√©gia-de-otimiza√ß√£o",
    "href": "abas/04_tunning.html#estrat√©gia-de-otimiza√ß√£o",
    "title": "4. üî¨ Tunning e Modelo de Regress√£o Log√≠stica Final",
    "section": "",
    "text": "O modelo foi otimizado utilizando o RandomizedSearchCV com Cross-Validation, buscando maximizar o KS Score, uma m√©trica cr√≠tica para separa√ß√£o de risco\nO processo de tunning focou na regulariza√ß√£o do modelo para evitar overfitting e garantir a robustez.\nMelhores Par√¢metros Encontrados:\n\n\n\nPar√¢metro\nValor Otimizado\n\n\n\n\nn_estimators\n800\n\n\nlearning_rate\n0.01\n\n\nsubsample\n0.7\n\n\nreg_alpha / reg_lambda\n0.0 / 0.0",
    "crumbs": [
      "04. Tunning"
    ]
  },
  {
    "objectID": "abas/00_introducao.html",
    "href": "abas/00_introducao.html",
    "title": "üìÑ Introdu√ß√£o: Constru√ß√£o do Modelo de Credit Scoring",
    "section": "",
    "text": "O presente relat√≥rio t√©cnico detalha a constru√ß√£o e valida√ß√£o de um modelo de Credit Scoring desenvolvido para apoiar a tomada de decis√£o em concess√£o de cr√©dito.\n\n\nO objetivo prim√°rio √© estimar a probabilidade de inadimpl√™ncia (default) de clientes em potencial, fornecendo um score robusto e interpret√°vel que permita a automa√ß√£o e otimiza√ß√£o das pol√≠ticas de risco do banco.\n\n\n\nA base de dados utilizada comp√µe-se de 10.738 registros e 81 vari√°veis mascaradas. O desenvolvimento do modelo √© guiado pela necessidade de transpar√™ncia e interpretabilidade, que s√£o cruciais para a governan√ßa e auditoria regulat√≥ria em institui√ß√µes financeiras.\n\n\n\nO projeto abrange o fluxo completo de Data Science, focado em entregar um modelo de Credit Scoring est√°vel e aplic√°vel ao neg√≥cio.\n\nA metodologia √© estruturada em quatro pilares:\n\nPr√©-processamento: Tratamento de dados, remo√ß√£o de redund√¢ncias (Multicolinearidade) e an√°lise de estabilidade das vari√°veis (PSI).\nModelagem e Sele√ß√£o: Compara√ß√£o de algoritmos (priorizando estabilidade e interpretabilidade) para identificar o melhor preditor.\nValida√ß√£o OOT: Teste rigoroso de desempenho em um conjunto Out-of-Time (OOT) (safras Outubro, Novembro e Dezembro), crucial para simular o risco futuro e comprovar a estabilidade temporal.\nRecomenda√ß√£o: An√°lise final de m√©tricas (AUC, Gini, KS) e calibra√ß√£o para definir o Scorecard e o ponto de corte ideal para a tomada de decis√£o de cr√©dito.",
    "crumbs": [
      "P√°gina inicial",
      "00. Introdu√ß√£o"
    ]
  },
  {
    "objectID": "abas/00_introducao.html#objetivo-central",
    "href": "abas/00_introducao.html#objetivo-central",
    "title": "üìÑ Introdu√ß√£o: Constru√ß√£o do Modelo de Credit Scoring",
    "section": "",
    "text": "O objetivo prim√°rio √© estimar a probabilidade de inadimpl√™ncia (default) de clientes em potencial, fornecendo um score robusto e interpret√°vel que permita a automa√ß√£o e otimiza√ß√£o das pol√≠ticas de risco do banco.",
    "crumbs": [
      "P√°gina inicial",
      "00. Introdu√ß√£o"
    ]
  },
  {
    "objectID": "abas/00_introducao.html#estrutura-do-desafio-e-dados",
    "href": "abas/00_introducao.html#estrutura-do-desafio-e-dados",
    "title": "üìÑ Introdu√ß√£o: Constru√ß√£o do Modelo de Credit Scoring",
    "section": "",
    "text": "A base de dados utilizada comp√µe-se de 10.738 registros e 81 vari√°veis mascaradas. O desenvolvimento do modelo √© guiado pela necessidade de transpar√™ncia e interpretabilidade, que s√£o cruciais para a governan√ßa e auditoria regulat√≥ria em institui√ß√µes financeiras.",
    "crumbs": [
      "P√°gina inicial",
      "00. Introdu√ß√£o"
    ]
  },
  {
    "objectID": "abas/00_introducao.html#escopo-e-metodologia-de-risco",
    "href": "abas/00_introducao.html#escopo-e-metodologia-de-risco",
    "title": "üìÑ Introdu√ß√£o: Constru√ß√£o do Modelo de Credit Scoring",
    "section": "",
    "text": "O projeto abrange o fluxo completo de Data Science, focado em entregar um modelo de Credit Scoring est√°vel e aplic√°vel ao neg√≥cio.\n\nA metodologia √© estruturada em quatro pilares:\n\nPr√©-processamento: Tratamento de dados, remo√ß√£o de redund√¢ncias (Multicolinearidade) e an√°lise de estabilidade das vari√°veis (PSI).\nModelagem e Sele√ß√£o: Compara√ß√£o de algoritmos (priorizando estabilidade e interpretabilidade) para identificar o melhor preditor.\nValida√ß√£o OOT: Teste rigoroso de desempenho em um conjunto Out-of-Time (OOT) (safras Outubro, Novembro e Dezembro), crucial para simular o risco futuro e comprovar a estabilidade temporal.\nRecomenda√ß√£o: An√°lise final de m√©tricas (AUC, Gini, KS) e calibra√ß√£o para definir o Scorecard e o ponto de corte ideal para a tomada de decis√£o de cr√©dito.",
    "crumbs": [
      "P√°gina inicial",
      "00. Introdu√ß√£o"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "üìÑ Introdu√ß√£o: Constru√ß√£o do Modelo de Credit Scoring",
    "section": "",
    "text": "O presente relat√≥rio t√©cnico detalha a constru√ß√£o e valida√ß√£o de um modelo de Credit Scoring desenvolvido para apoiar a tomada de decis√£o em concess√£o de cr√©dito.\n\n\nO objetivo prim√°rio √© estimar a probabilidade de inadimpl√™ncia (default) de clientes em potencial, fornecendo um score robusto e interpret√°vel que permita a automa√ß√£o e otimiza√ß√£o das pol√≠ticas de risco do banco.\n\n\n\nA base de dados utilizada comp√µe-se de 10.738 registros e 81 vari√°veis mascaradas. O desenvolvimento do modelo √© guiado pela necessidade de transpar√™ncia e interpretabilidade, que s√£o cruciais para a governan√ßa e auditoria regulat√≥ria em institui√ß√µes financeiras.\n\n\n\nO projeto abrange o fluxo completo de Data Science, focado em entregar um modelo de Credit Scoring est√°vel e aplic√°vel ao neg√≥cio.\nA metodologia √© estruturada em quatro pilares:\n\n\nPr√©-processamento: Tratamento de dados, remo√ß√£o de redund√¢ncias (Multicolinearidade) e an√°lise de estabilidade das vari√°veis (PSI).\nModelagem e Sele√ß√£o: Compara√ß√£o de algoritmos (priorizando estabilidade e interpretabilidade) para identificar o melhor preditor.\nValida√ß√£o OOT: Teste rigoroso de desempenho em um conjunto Out-of-Time (OOT) (safras Outubro, Novembro e Dezembro), crucial para simular o risco futuro e comprovar a estabilidade temporal.\nRecomenda√ß√£o: An√°lise final de m√©tricas (AUC, Gini, KS) e calibra√ß√£o para definir o Scorecard e o ponto de corte ideal para a tomada de decis√£o de cr√©dito.",
    "crumbs": [
      "00. Introdu√ß√£o"
    ]
  },
  {
    "objectID": "index.html#objetivo-central",
    "href": "index.html#objetivo-central",
    "title": "üìÑ Introdu√ß√£o: Constru√ß√£o do Modelo de Credit Scoring",
    "section": "",
    "text": "O objetivo prim√°rio √© estimar a probabilidade de inadimpl√™ncia (default) de clientes em potencial, fornecendo um score robusto e interpret√°vel que permita a automa√ß√£o e otimiza√ß√£o das pol√≠ticas de risco do banco.",
    "crumbs": [
      "00. Introdu√ß√£o"
    ]
  },
  {
    "objectID": "index.html#estrutura-do-desafio-e-dados",
    "href": "index.html#estrutura-do-desafio-e-dados",
    "title": "üìÑ Introdu√ß√£o: Constru√ß√£o do Modelo de Credit Scoring",
    "section": "",
    "text": "A base de dados utilizada comp√µe-se de 10.738 registros e 81 vari√°veis mascaradas. O desenvolvimento do modelo √© guiado pela necessidade de transpar√™ncia e interpretabilidade, que s√£o cruciais para a governan√ßa e auditoria regulat√≥ria em institui√ß√µes financeiras.",
    "crumbs": [
      "00. Introdu√ß√£o"
    ]
  },
  {
    "objectID": "index.html#escopo-e-metodologia-de-risco",
    "href": "index.html#escopo-e-metodologia-de-risco",
    "title": "üìÑ Introdu√ß√£o: Constru√ß√£o do Modelo de Credit Scoring",
    "section": "",
    "text": "O projeto abrange o fluxo completo de Data Science, focado em entregar um modelo de Credit Scoring est√°vel e aplic√°vel ao neg√≥cio.\nA metodologia √© estruturada em quatro pilares:\n\n\nPr√©-processamento: Tratamento de dados, remo√ß√£o de redund√¢ncias (Multicolinearidade) e an√°lise de estabilidade das vari√°veis (PSI).\nModelagem e Sele√ß√£o: Compara√ß√£o de algoritmos (priorizando estabilidade e interpretabilidade) para identificar o melhor preditor.\nValida√ß√£o OOT: Teste rigoroso de desempenho em um conjunto Out-of-Time (OOT) (safras Outubro, Novembro e Dezembro), crucial para simular o risco futuro e comprovar a estabilidade temporal.\nRecomenda√ß√£o: An√°lise final de m√©tricas (AUC, Gini, KS) e calibra√ß√£o para definir o Scorecard e o ponto de corte ideal para a tomada de decis√£o de cr√©dito.",
    "crumbs": [
      "00. Introdu√ß√£o"
    ]
  },
  {
    "objectID": "abas/02_feature_engineering.html#population-stability-index-psi",
    "href": "abas/02_feature_engineering.html#population-stability-index-psi",
    "title": "‚öôÔ∏è 2. Feature Engineering e Sele√ß√£o de Vari√°veis",
    "section": "",
    "text": "A estabilidade das features entre a amostra de Treino e a amostra de Teste (Out-of-Time) √© cr√≠tica para a robustez do modelo. Utilizei o Population Stability Index (PSI).\nPSI: O PSI mede o drift (deslocamento) na distribui√ß√£o de uma vari√°vel entre duas popula√ß√µes.\n\nPSI &lt; 0.1: Distribui√ß√£o Est√°vel\n0.1 &lt; ou = PSI &lt; 0.25: Mudan√ßa Moderada\nPSI &gt; ou = 0.25: Mudan√ßa Forte\n\nNenhuma feature atingiu o limite de Mudan√ßa Forte. As vari√°veis VAR_30 e VAR_1 apresentam Mudan√ßa Moderada. Embora n√£o sejam descartadas neste momento, elas ser√£o monitoradas na pr√≥xima etapa.\nConclus√£o e Pr√≥xima Etapa: Ap√≥s o processo de Feature Engineering e Sele√ß√£o, o n√∫mero de vari√°veis preditoras foi reduzido de 78 para 47 features (al√©m das colunas protegidas).",
    "crumbs": [
      "02. Feature Enginee"
    ]
  },
  {
    "objectID": "abas/01_exploratory_data_analysis.html",
    "href": "abas/01_exploratory_data_analysis.html",
    "title": "1. üìÑ An√°lise Explorat√≥ria de Dados (EDA)",
    "section": "",
    "text": "Este cap√≠tulo apresenta a estrutura da base de dados, a defini√ß√£o da vari√°vel alvo (target) e as an√°lises iniciais de qualidade e distribui√ß√£o de risco.\n\n\n\nA base de dados bruta cont√©m 10.738 observa√ß√µes e 81 colunas (incluindo id, safra e features).\nDefini√ß√£o da Vari√°vel Alvo (y)\n\ny = 1 (Mau Pagador): Inadimpl√™ncia (default)\ny = 0 (Bom Pagador): N√£o-inadimpl√™ncia\n\nA Taxa de Inadimpl√™ncia Global da amostra √© de 29,13%.\n\n\n\nClasse\nContagem Absoluta\nPropor√ß√£o\n\n\n\n\n0 (Bom Pagador)\n7.610\n70,87%\n\n\n1 (Mau Pagador)\n3.128\n29,13%\n\n\n\n\n\n\n\nA an√°lise do risco ao longo do tempo (safra) √© crucial em cr√©dito. A base abrange 12 meses, de 01/2014 a 12/2014.\nO gr√°fico abaixo mostra a varia√ß√£o da taxa de inadimpl√™ncia (m√©dia de y) em cada safra.\n\nA taxa de inadimpl√™ncia demonstra uma tend√™ncia de aumento nas safras finais (11/2014 e 12/2014), atingindo o pico de 35,24% na √∫ltima safra. Este pico √© significativamente maior do que a m√©dia da amostra (29,13%), sugerindo uma poss√≠vel instabilidade temporal ou uma mudan√ßa no perfil de risco dos clientes mais recentes.\n\n\n\n\nPara garantir que o modelo de Credit Scoring seja robusto ao longo do tempo, √© essencial monitorar as features mais preditivas e verificar se suas distribui√ß√µes se mant√™m est√°veis ao longo das safras.\nGr√°fico de estabilidade da VAR_1:\n\n\n\n\n\nA qualidade dos dados foi avaliada, com foco na presen√ßa de valores ausentes (Missing Values).\nTotal de Features Analisadas: 78 Amostra Total: 10.738 linhas\n\nConclus√£o e Pr√≥xima Etapa: H√° uma grande quantidade de vari√°veis com uma alta percentagem de valores ausentes (mais de 50%). Na fase 02_feature_engineering.ipynb, ser√° necess√°rio definir um limite de corte para descarte de vari√°veis.",
    "crumbs": [
      "01. Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "abas/01_exploratory_data_analysis.html#defini√ß√£o-do-target-e-distribui√ß√£o-da-amostra",
    "href": "abas/01_exploratory_data_analysis.html#defini√ß√£o-do-target-e-distribui√ß√£o-da-amostra",
    "title": "1. üìÑ An√°lise Explorat√≥ria de Dados (EDA)",
    "section": "",
    "text": "A base de dados bruta cont√©m 10.738 observa√ß√µes e 81 colunas (incluindo id, safra e features).\nDefini√ß√£o da Vari√°vel Alvo (y)\n\ny = 1 (Mau Pagador): Inadimpl√™ncia (default)\ny = 0 (Bom Pagador): N√£o-inadimpl√™ncia\n\nA Taxa de Inadimpl√™ncia Global da amostra √© de 29,13%.\n\n\n\nClasse\nContagem Absoluta\nPropor√ß√£o\n\n\n\n\n0 (Bom Pagador)\n7.610\n70,87%\n\n\n1 (Mau Pagador)\n3.128\n29,13%",
    "crumbs": [
      "01. Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "abas/01_exploratory_data_analysis.html#estabilidade-temporal-da-inadimpl√™ncia-an√°lise-por-safra",
    "href": "abas/01_exploratory_data_analysis.html#estabilidade-temporal-da-inadimpl√™ncia-an√°lise-por-safra",
    "title": "1. üìÑ An√°lise Explorat√≥ria de Dados (EDA)",
    "section": "",
    "text": "A an√°lise do risco ao longo do tempo (safra) √© crucial em cr√©dito. A base abrange 12 meses, de 01/2014 a 12/2014.\nO gr√°fico abaixo mostra a varia√ß√£o da taxa de inadimpl√™ncia (m√©dia de y) em cada safra.\n\nA taxa de inadimpl√™ncia demonstra uma tend√™ncia de aumento nas safras finais (11/2014 e 12/2014), atingindo o pico de 35,24% na √∫ltima safra. Este pico √© significativamente maior do que a m√©dia da amostra (29,13%), sugerindo uma poss√≠vel instabilidade temporal ou uma mudan√ßa no perfil de risco dos clientes mais recentes.",
    "crumbs": [
      "01. Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "abas/01_exploratory_data_analysis.html#qualidade-e-sa√∫de-dos-dados-valores-ausentes",
    "href": "abas/01_exploratory_data_analysis.html#qualidade-e-sa√∫de-dos-dados-valores-ausentes",
    "title": "1. üìÑ An√°lise Explorat√≥ria de Dados (EDA)",
    "section": "",
    "text": "A qualidade dos dados foi avaliada, com foco na presen√ßa de valores ausentes (Missing Values).\nTotal de Features Analisadas: 78 Amostra Total: 10.738 linhas\n\nConclus√£o e Pr√≥xima Etapa: H√° uma grande quantidade de vari√°veis com uma alta percentagem de valores ausentes (mais de 50%). Na fase 02_feature_engineering.ipynb, ser√° necess√°rio definir um limite de corte para descarte de vari√°veis.",
    "crumbs": [
      "01. Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "abas/01_exploratory_data_analysis.html#estabilidade-das-vari√°veis-por-safra",
    "href": "abas/01_exploratory_data_analysis.html#estabilidade-das-vari√°veis-por-safra",
    "title": "1. üìÑ An√°lise Explorat√≥ria de Dados (EDA)",
    "section": "",
    "text": "Para garantir que o modelo de Credit Scoring seja robusto ao longo do tempo, √© essencial monitorar as features mais preditivas e verificar se suas distribui√ß√µes se mant√™m est√°veis ao longo das safras.\nGr√°fico de estabilidade da VAR_1:",
    "crumbs": [
      "01. Exploratory Data Analysis"
    ]
  },
  {
    "objectID": "abas/02_feature_engineering.html#classifica√ß√£o-de-vari√°veis-categ√≥ricas-vs.-num√©ricas",
    "href": "abas/02_feature_engineering.html#classifica√ß√£o-de-vari√°veis-categ√≥ricas-vs.-num√©ricas",
    "title": "‚öôÔ∏è 2. Feature Engineering e Sele√ß√£o de Vari√°veis",
    "section": "",
    "text": "A classifica√ß√£o correta das vari√°veis √© um passo essencial para garantir que o pr√©-processamento subsequente seja aplicado de forma adequada (ex: One-Hot Encoding para categ√≥ricas, Scaling para num√©ricas).\n\n\nDada a natureza mascarada das features, a distin√ß√£o entre vari√°veis cont√≠nuas e discretas foi feita utilizando a Cardinalidade (n√∫mero de valores √∫nicos) como crit√©rio principal.\nThreshold Definido: Foi estabelecido um threshold de 25 valores √∫nicos.\n\nVari√°veis Categ√≥ricas (CAT_VARS): Features com at√© 25 valores √∫nicos foram classificadas como categ√≥ricas, pois representam um conjunto discreto e gerenci√°vel de classes.\nVari√°veis Num√©ricas (NUM_VARS): Features com mais de 25 valores √∫nicos foram classificadas como num√©ricas, indicando uma distribui√ß√£o de dados cont√≠nua ou de alta vari√¢ncia.\n\n\n\n\nAp√≥s a classifica√ß√£o, as features em CAT_VARS foram explicitamente convertidas para o tipo object (tipo Python para string ou categoria). Esta convers√£o √© necess√°ria para garantir que os pipelines de pr√©-processamento (como OneHotEncoder ou o uso futuro de WOE) as tratem corretamente, independentemente de seu tipo original.",
    "crumbs": [
      "02. Feature Enginee"
    ]
  },
  {
    "objectID": "abas/05_final_model.html",
    "href": "abas/05_final_model.html",
    "title": "5. üöÄ Valida√ß√£o do Modelo Final (LightGBM)",
    "section": "",
    "text": "Esta fase consolida a performance do modelo LightGBM tunado, analisando em profundidade a separa√ß√£o de risco (ROC/KS), a distribui√ß√£o do score (Taxa de Evento por Quantil) e a calibra√ß√£o da probabilidade de default no conjunto de Teste OOT.\n\n\n\nO modelo final (LightGBM) foi avaliado em ambos os conjuntos.\n\n\n\n\n\n\n\n\n\n\n\n\n\nBase\nAUC\nKS\nGini\nAccuracy\nPrecision\nRecall\nF1\n\n\n\n\nTreino\n0.954\n0.766\n0.908\n0.878\n0.904\n0.634\n0.745\n\n\nTeste (OOT)\n0.708\n0.314\n0.417\n0.694\n0.589\n0.159\n0.250\n\n\n\nA alta performance no Treino (AUC = 0.95) comparada √† performance no Teste OOT (AUC = 0.708) demonstra um alto grau de overfitting, comum em modelos de ensemble que buscam a m√°xima acur√°cia. No entanto, o AUC de 0.708 no OOT confirma que o modelo reteve um poder de separa√ß√£o de risco robusto.\n\n\n\n\n\n\nA Curva ROC no Teste OOT confirma o poder de ranqueamento, com um AUC de 0.708.\n\n\n\n\nO KS Score de 0.314 indica que a separa√ß√£o m√°xima entre a distribui√ß√£o acumulada de Bons e Maus Pagadores √© de 31.4%, um resultado satisfat√≥rio.\n\n\n\n\n\n\nA an√°lise por quantis (decis) √© a tradu√ß√£o mais direta do poder de ranqueamento para o neg√≥cio, mostrando a concentra√ß√£o de risco.\nO gr√°fico de Taxa de Evento compara a frequ√™ncia observada de default por faixas de score (quantis) no Treino e no Teste OOT.\n\n\n\n\n\nKS por Safra\nA an√°lise do KS m√™s a m√™s (por safra) √© a verifica√ß√£o mais rigorosa da estabilidade preditiva ao longo do tempo.\n\nNota: O KS no Teste OOT (safras 10/2014 a 12/2014) mostra uma queda de performance na √∫ltima safra (12/2014) (KS = 0.258). Isso pode ser um sinal de forte drift de mercado ou mudan√ßa de pol√≠tica de cr√©dito recente, exigindo monitoramento imediato.\nCurva de Calibra√ß√£o\nA curva de calibra√ß√£o verifica se a probabilidade prevista (P(Default)) corresponde √† frequ√™ncia real de default observada.",
    "crumbs": [
      "05. Final Model"
    ]
  },
  {
    "objectID": "abas/05_final_model.html#m√©tricas-de-desempenho-finais",
    "href": "abas/05_final_model.html#m√©tricas-de-desempenho-finais",
    "title": "5. üöÄ Valida√ß√£o do Modelo Final (LightGBM)",
    "section": "",
    "text": "O modelo final (LightGBM) foi avaliado em ambos os conjuntos.\n\n\n\n\n\n\n\n\n\n\n\n\n\nBase\nAUC\nKS\nGini\nAccuracy\nPrecision\nRecall\nF1\n\n\n\n\nTreino\n0.954\n0.766\n0.908\n0.878\n0.904\n0.634\n0.745\n\n\nTeste (OOT)\n0.708\n0.314\n0.417\n0.694\n0.589\n0.159\n0.250\n\n\n\nA alta performance no Treino (AUC = 0.95) comparada √† performance no Teste OOT (AUC = 0.708) demonstra um alto grau de overfitting, comum em modelos de ensemble que buscam a m√°xima acur√°cia. No entanto, o AUC de 0.708 no OOT confirma que o modelo reteve um poder de separa√ß√£o de risco robusto.",
    "crumbs": [
      "05. Final Model"
    ]
  },
  {
    "objectID": "abas/05_final_model.html#curvas-de-ranqueamento",
    "href": "abas/05_final_model.html#curvas-de-ranqueamento",
    "title": "5. üöÄ Valida√ß√£o do Modelo Final (LightGBM)",
    "section": "",
    "text": "A Curva ROC no Teste OOT confirma o poder de ranqueamento, com um AUC de 0.708.\n\n\n\n\nO KS Score de 0.314 indica que a separa√ß√£o m√°xima entre a distribui√ß√£o acumulada de Bons e Maus Pagadores √© de 31.4%, um resultado satisfat√≥rio.",
    "crumbs": [
      "05. Final Model"
    ]
  },
  {
    "objectID": "abas/05_final_model.html#taxa-de-evento-por-quantil-lift-analysis",
    "href": "abas/05_final_model.html#taxa-de-evento-por-quantil-lift-analysis",
    "title": "5. üöÄ Valida√ß√£o do Modelo Final (LightGBM)",
    "section": "",
    "text": "A an√°lise por quantis (decis) √© a tradu√ß√£o mais direta do poder de ranqueamento para o neg√≥cio, mostrando a concentra√ß√£o de risco.\nO gr√°fico de Taxa de Evento compara a frequ√™ncia observada de default por faixas de score (quantis) no Treino e no Teste OOT.",
    "crumbs": [
      "05. Final Model"
    ]
  },
  {
    "objectID": "abas/05_final_model.html#estabilidade-temporal-do-ks-e-calibra√ß√£o",
    "href": "abas/05_final_model.html#estabilidade-temporal-do-ks-e-calibra√ß√£o",
    "title": "5. üöÄ Valida√ß√£o do Modelo Final (LightGBM)",
    "section": "",
    "text": "KS por Safra\nA an√°lise do KS m√™s a m√™s (por safra) √© a verifica√ß√£o mais rigorosa da estabilidade preditiva ao longo do tempo.\n\nNota: O KS no Teste OOT (safras 10/2014 a 12/2014) mostra uma queda de performance na √∫ltima safra (12/2014) (KS = 0.258). Isso pode ser um sinal de forte drift de mercado ou mudan√ßa de pol√≠tica de cr√©dito recente, exigindo monitoramento imediato.\nCurva de Calibra√ß√£o\nA curva de calibra√ß√£o verifica se a probabilidade prevista (P(Default)) corresponde √† frequ√™ncia real de default observada.",
    "crumbs": [
      "05. Final Model"
    ]
  },
  {
    "objectID": "abas/04_tunning.html#performance-final-do-lightgbm-teste-oot",
    "href": "abas/04_tunning.html#performance-final-do-lightgbm-teste-oot",
    "title": "4. üî¨ Tunning e Modelo de Regress√£o Log√≠stica Final",
    "section": "",
    "text": "O modelo otimizado foi treinado na base completa de Treino e avaliado no conjunto de Teste OOT, confirmando seu potencial m√°ximo.\n\n\n\nM√©trica\nValor\n\n\n\n\nKS\n0.313688\n\n\nAUC\n0.708333\n\n\nGini\n0.416665\n\n\n\nAp√≥s o tunning, o LightGBM alcan√ßou o melhor desempenho absoluto no Teste OOT, com AUC de 0.708 e Gini de 0.417. Este resultado supera o modelo de Regress√£o Log√≠stica (AUC 0.701) e confirma o LightGBM como o modelo mais preditivo para o Scorecard.",
    "crumbs": [
      "04. Tunning"
    ]
  }
]