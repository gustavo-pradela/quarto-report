# üß† 3. Modelagem e Sele√ß√£o Final do Modelo

Esta se√ß√£o detalha o **pr√©-processamento final das features**, a sele√ß√£o de vari√°veis baseada em import√¢ncia e a avalia√ß√£o comparativa de diferentes algoritmos de Machine Learning.

---

## 3.1. üî¨ Pr√©-processamento e Pipelines

Todas as 47 features restantes foram submetidas a um Pipeline de pr√©-processamento padr√£o:

>**Imputa√ß√£o de Missing Values:** Utiliza√ß√£o da mediana para preencher valores ausentes nas vari√°veis num√©ricas e moda nas vari√°veis categ√≥ricas.
>
>**Padroniza√ß√£o (StandardScaler e One-Hot Encoding):** Aplica√ß√£o do StandardScaler para normalizar as features n√∫mericas e One-Hot Encoding para as features categ√≥ricas.

---

## 3.2. üå≥ Sele√ß√£o Final de Vari√°veis (Random Forest)

Para refinar o modelo e reduzir a complexidade e o risco de overfitting, foi utilizado um modelo Random Forest para ranquear as features por import√¢ncia (Feature Importance).

Objetivo: Selecionar as Top K=20 vari√°veis que mais contribuem para a separa√ß√£o entre _Bons_ e _Maus Pagadores_.

![](../images/image-2.png)

O dataset para o treinamento final foi **reduzido de 47 para 20 features**, focado nas vari√°veis com maior _poder preditivo_.

---

## 3.3. üÜö Avalia√ß√£o Comparativa de Modelos (Cross-Validation)

Quatro modelos foram comparados utilizando Cross-Validation Estratificada (5 splits) no conjunto de Treino (X_train_sel).

### 3.3.1. M√©tricas de Desempenho

Em Credit Scoring, as m√©tricas de ranking s√£o priorizadas:


>**AUC (Area Under the Curve):** Probabilidade de o modelo ranquear um par aleat√≥rio (Mau Pagador, Bom Pagador) na ordem correta. 
>
>**Gini Coefficient:** Mede a separa√ß√£o das distribui√ß√µes.
>
>**KS (Kolmogorov-Smirnov):** Mede a separa√ß√£o m√°xima entre as distribui√ß√µes acumuladas de _Bons_ e _Maus Pagadores_.


| Modelo | KS M√©dio | KS Desvio | AUC M√©dio | AUC Desvio | Gini M√©dio | Gini Desvio |
| :--- | :---: | :---: | :---: | :---: | :---: | :---: |
| **LightGBM** | **0.447** | 0.022 | **0.796** | 0.011 | **0.593** | 0.022 |
| Logistic Regression | 0.424 | 0.013 | 0.786 | 0.011 | 0.571 | 0.022 |
| Random Forest | 0.433 | 0.019 | 0.785 | 0.009 | 0.569 | 0.017 |
| XGBoost | 0.424 | 0.034 | 0.783 | 0.015 | 0.566 | 0.029 |

**Conclus√£o do Treino:** O LightGBM demonstrou o melhor desempenho preditivo bruto, estabelecendo o teto da performance com o maior AUC (0.796) e Gini (0.593). A Regress√£o Log√≠stica e o Random Forest se mostraram altamente competitivos, ficando a menos de 1 ponto percentual de dist√¢ncia no AUC.

---

## 3.4. üõ°Ô∏è Valida√ß√£o Final (Teste OOT)

A performance de cada modelo foi avaliada no conjunto de **Teste (Out-of-Time - OOT)**, que representa o ambiente de risco futuro. A estabilidade √© medida pela capacidade do modelo de reter seu poder preditivo em dados futuros (OOT).

| Modelo | KS | AUC | Gini |
| :--- | :---: | :---: | :---: |
| **LightGBM** | **0.306** | **0.704** | **0.407** |
| Logistic Regression | 0.294 | 0.701 | 0.402 |
| Random Forest | 0.265 | 0.685 | 0.369 |
| XGBoost | 0.255 | 0.668 | 0.337 |


**Conclus√£o:** Devido a sua performance superior, o **LightGBM √© o modelo escolhido para o Credit Scoring final.**

---