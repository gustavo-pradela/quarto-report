# 4. üî¨ Tunning e Modelo de Regress√£o Log√≠stica Final

Nesta etapa, o modelo de Regress√£o Log√≠stica escolhido na Etapa 3 √© **otimizado** usando pesquisa de hiperpar√¢metros e, em seguida, validado no conjunto de Teste Out-of-Time (OOT).

---

## 4.1. ‚öôÔ∏è Estrat√©gia de Otimiza√ß√£o

O modelo foi otimizado utilizando o **RandomizedSearchCV** com **Cross-Validation**, buscando maximizar o KS Score, uma m√©trica cr√≠tica para separa√ß√£o de risco

O processo de tunning focou na regulariza√ß√£o do modelo para evitar overfitting e garantir a robustez.

**Melhores Par√¢metros Encontrados:**

| Par√¢metro | Valor Otimizado |
| :--- | :---: |
| **`n_estimators`** | 800 |
| **`learning_rate`** | 0.01 |
| **`subsample`** | 0.7 |
| **`reg_alpha` / `reg_lambda`** | 0.0 / 0.0 |

---

## 4.2. üéØ Performance Final do LightGBM (Teste OOT)

O modelo otimizado foi treinado na base completa de Treino e avaliado no conjunto de Teste OOT, confirmando seu potencial m√°ximo.

| M√©trica | Valor |
| :--- | :---: |
| **KS** | 0.313688 |
| **AUC** | 0.708333 |
| **Gini** | 0.416665 |

Ap√≥s o tunning, o LightGBM alcan√ßou o melhor desempenho absoluto no Teste OOT, com **AUC** de **0.708** e **Gini** de **0.417**. Este resultado supera o modelo de Regress√£o Log√≠stica (AUC 0.701) e confirma o **LightGBM como o modelo mais preditivo para o Scorecard.**